{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "687c3d52-9fab-4e8b-958b-46d7b38ead16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f9da3fe3-9335-494a-afaa-81f1726c1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze = pd.read_csv('data/payments_main.tsv',index_col=False,sep='\\t', names = ['id','date','payment','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9b1a101e-acd9-4e7c-9328-d7ba9c2f7b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>payment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>07.11.2024</td>\n",
       "      <td>40500.00</td>\n",
       "      <td>За тур.поездку по договору №001 от 27.01.2023г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>07.11.2024</td>\n",
       "      <td>32600,00</td>\n",
       "      <td>За оказание услуг по договору №53Б-02746 от 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>07.11.2024</td>\n",
       "      <td>4710-00</td>\n",
       "      <td>Оплата штрафа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>07.11.2024</td>\n",
       "      <td>30900-00</td>\n",
       "      <td>Лечение по договору №Д-00359/24 от 08.03.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>07.11.2024</td>\n",
       "      <td>13200.00</td>\n",
       "      <td>Оплата основного долга за период с 16.12.2024г...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date   payment                                               text\n",
       "0   1  07.11.2024  40500.00     За тур.поездку по договору №001 от 27.01.2023г\n",
       "1   2  07.11.2024  32600,00  За оказание услуг по договору №53Б-02746 от 23...\n",
       "2   3  07.11.2024   4710-00                                      Оплата штрафа\n",
       "3   4  07.11.2024  30900-00      Лечение по договору №Д-00359/24 от 08.03.2025\n",
       "4   5  07.11.2024  13200.00  Оплата основного долга за период с 16.12.2024г..."
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyze.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "41d08b14-f9f7-419d-a69d-c5c1717a3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze = df_analyze.drop(columns = ['id','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "175744bf-a315-4ab2-9ee0-f011214e5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40500.00</td>\n",
       "      <td>За тур.поездку по договору №001 от 27.01.2023г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32600,00</td>\n",
       "      <td>За оказание услуг по договору №53Б-02746 от 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4710-00</td>\n",
       "      <td>Оплата штрафа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30900-00</td>\n",
       "      <td>Лечение по договору №Д-00359/24 от 08.03.2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13200.00</td>\n",
       "      <td>Оплата основного долга за период с 16.12.2024г...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    payment                                               text\n",
       "0  40500.00     За тур.поездку по договору №001 от 27.01.2023г\n",
       "1  32600,00  За оказание услуг по договору №53Б-02746 от 23...\n",
       "2   4710-00                                      Оплата штрафа\n",
       "3  30900-00      Лечение по договору №Д-00359/24 от 08.03.2025\n",
       "4  13200.00  Оплата основного долга за период с 16.12.2024г..."
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ec07c-284f-4b63-a29d-3f23289a23b7",
   "metadata": {},
   "source": [
    "#### Step-1: Remove non-cyrillic symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4b787fe6-dd42-42d9-a5eb-d1c96c94f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_cyrillic(text):\n",
    " cyrillic_pattern = r\"[^а-яА-ЯёЁ]+\"\n",
    " cleaned_text = re.sub(cyrillic_pattern, \" \", text)\n",
    " return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b9cb8c85-1e37-4cea-9c9b-a42c6d53b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze['text'] = df_analyze['text'].apply(remove_non_cyrillic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "510631ed-28a5-4118-8ede-d44fee3d27ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40500.00</td>\n",
       "      <td>За тур поездку по договору от г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32600,00</td>\n",
       "      <td>За оказание услуг по договору Б от</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4710-00</td>\n",
       "      <td>Оплата штрафа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30900-00</td>\n",
       "      <td>Лечение по договору Д от</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13200.00</td>\n",
       "      <td>Оплата основного долга за период с г по марта ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    payment                                               text\n",
       "0  40500.00                    За тур поездку по договору от г\n",
       "1  32600,00                За оказание услуг по договору Б от \n",
       "2   4710-00                                      Оплата штрафа\n",
       "3  30900-00                          Лечение по договору Д от \n",
       "4  13200.00  Оплата основного долга за период с г по марта ..."
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3accdfb3-a610-41a1-b35d-e9555954741b",
   "metadata": {},
   "source": [
    "#### Step-1.5 Remove joined words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a2e64-ec9f-4181-82c1-9593d55f9b86",
   "metadata": {},
   "source": [
    "def split_joined_words(text):\n",
    "    splited_text = text.split(' ')\n",
    "    tokens = []\n",
    "    splited = False\n",
    "    for token in splited_text:\n",
    "        splited = False\n",
    "        for i in range(1, len(token)):\n",
    "            token = token.strip()\n",
    "            if not token[i-1].isupper() and token[i].isupper():\n",
    "                token1,token2 = token[0:i], token[i:]\n",
    "                splited = True\n",
    "                print(token1,token2)\n",
    "                tokens.append(f' {token1} ')\n",
    "                tokens.append(f' {token2} ')\n",
    "        if splited is False:\n",
    "            tokens.append(f' {token} ')\n",
    "    return ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "441cced3-9db1-43f6-a6d1-084d193037c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_joined_words(text):\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    def split_token(split_points, text):           \n",
    "        for i in range(1,len(split_points)):\n",
    "            token = text[split_points[i-1]:split_points[i]]\n",
    "            tokens.append(f' {token} ')\n",
    "    \n",
    "    splited_text = text.split(' ')\n",
    "    for token in splited_text:\n",
    "        split_points = [0]\n",
    "        for i in range(1, len(token)):\n",
    "            token = token.strip()\n",
    "            if not token[i-1].isupper() and token[i].isupper():\n",
    "                split_points.append(i)\n",
    "        split_points.append(len(token))\n",
    "        split_token(split_points,token)\n",
    "                \n",
    "    return ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "40c63c17-90c2-4db1-b089-398cf4267d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze['text'] = df_analyze['text'].apply(split_joined_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be55cb7d-b99e-4a35-b69e-469e35993112",
   "metadata": {},
   "source": [
    "#### Step-2: Apply stop words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a86bd155-6ad3-4d5c-81fd-06f46cd51f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ru = stopwords.words(\"russian\")\n",
    "stopwords_ru.extend( {\"по\", \"от\", \"до\", \"с\", \"в\", \"на\", \"за\", \"к\", \"о\", \"об\", \"у\", \"со\", \"из\", \"при\", \"под\", \"про\", \"через\", \"над\", \"без\"})\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0696fbea-78c0-4085-9ff8-348bf717612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    text_splited = text.split(' ')\n",
    "    filtered_tokens = []\n",
    "    for token in text_splited:\n",
    "        if token not in stopwords_ru:\n",
    "            token = token.strip()\n",
    "            token = morph.normal_forms(token)[0]\n",
    "            if len(token) < 2: # Отсев единичных букв\n",
    "                continue\n",
    "            filtered_tokens.append(f' {token} ')\n",
    "    # if len(filtered_tokens) <= 2:\n",
    "    #    return None # ( ' ' ?)\n",
    "    return ''.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "64da96c3-9798-4348-b0c8-e5016433d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze['text'] = df_analyze['text'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ee127f64-95f7-477d-85ee-2f3d8ab6237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40500.00</td>\n",
       "      <td>за  тур  поездка  договор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32600,00</td>\n",
       "      <td>за  оказание  услуга  договор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4710-00</td>\n",
       "      <td>оплата  штраф</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30900-00</td>\n",
       "      <td>лечение  договор  далее</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13200.00</td>\n",
       "      <td>оплата  основный  долг  период  март  договор...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    payment                                               text\n",
       "0  40500.00                         за  тур  поездка  договор \n",
       "1  32600,00                     за  оказание  услуга  договор \n",
       "2   4710-00                                     оплата  штраф \n",
       "3  30900-00                           лечение  договор  далее \n",
       "4  13200.00   оплата  основный  долг  период  март  договор..."
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyze.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae3a97-3e71-45b3-937c-e6f1435eb6a2",
   "metadata": {},
   "source": [
    "#### Step-3: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fd71bc76-5f07-4715-92c9-891f741412ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_analyze['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5f33ce13-ff99-4d3c-99b4-426b7619365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Уникальных токенов: 1786\n"
     ]
    }
   ],
   "source": [
    "texts_raw = texts.values\n",
    "unique_tokens = []\n",
    "for text in texts_raw:\n",
    "    tokens = text.split(' ')\n",
    "    for token in tokens:\n",
    "        if token not in unique_tokens:\n",
    "            unique_tokens.append(token)\n",
    "\n",
    "count_unique_tokens = len(unique_tokens)\n",
    "print(f' Уникальных токенов: {count_unique_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f713deba-fefc-439a-8a95-a5051e8079e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=count_unique_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a9f301b4-244b-480f-980a-071c24e9652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf.fit_transform(texts).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ea13c-4c8b-4f58-abf9-27da1cf6d445",
   "metadata": {},
   "source": [
    "#### Step-4: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "851c983b-4896-481f-979e-16721b70ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_transform = PCA(n_components = 744)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c936d37b-a7b7-4ac1-8685-a321d26a2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_compressed = pca_transform.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2f404444-b5aa-4ee8-8549-59701eb218cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Компонент до сжатия: 1785, компонент после сжатия: 744\n"
     ]
    }
   ],
   "source": [
    "print(f'Компонент до сжатия: {tfidf_matrix.shape[1]}, компонент после сжатия: {tfidf_matrix_compressed.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6c21a73c-9324-45a2-9958-1496b323ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Величина объясненной дисперсии: 0.9744697971216831\n"
     ]
    }
   ],
   "source": [
    "explained_variance = np.sum(pca_transform.explained_variance_ratio_)\n",
    "print(f'Величина объясненной дисперсии: {explained_variance }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
